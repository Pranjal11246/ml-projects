{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "605b787e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: I am feeling very happy today!!!...\n"
     ]
    }
   ],
   "source": [
    "text = \"I am feeling very happy today!!!...\"\n",
    "print(\"Original text:\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7055e776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowercase text: i am feeling very happy today!!!...\n"
     ]
    }
   ],
   "source": [
    "text = text.lower() #Step 1: Convert to lowercase because \"Happy\" and \"happy\" should be treated the same so ML will consider these two as different words.\n",
    "print(\"Lowercase text:\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55fdbd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text without punctuation: i am feeling very happy today\n"
     ]
    }
   ],
   "source": [
    "#step 2: Remove punctuation as we remove everything except letters and spaces\n",
    "import re #regular expression library \n",
    "text= re.sub(r'[^\\w\\s]','',text) #\\w means word character, \\s means space, ^ means not, so this regex means remove everything except word characters and spaces\n",
    "print(\"Text without punctuation:\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07c1cc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:  ['i', 'am', 'feeling', 'very', 'happy', 'today']\n"
     ]
    }
   ],
   "source": [
    "#Step 3: Tokenization: Split the text into individual words (tokens)\n",
    "tokens= text.split()\n",
    "print(\"Tokens: \",tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6139a682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered tokens:  ['feeling', 'happy', 'today']\n"
     ]
    }
   ],
   "source": [
    "#step 4:remove stopwords: Stopwords are common words that do not carry much meaning and can be removed to reduce noise in the data. Examples of stopwords include \"the\", \"is\", \"in\", \"and\", etc.\n",
    "stopwords = [\"i\",\"am\",\"is\",\"in\",\"and\",\"the\",\"a\",\"an\",\"to\",\"of\",\"very\"] \n",
    "filtered_tokens=[]\n",
    "for word in tokens:\n",
    "    if(word not in stopwords):\n",
    "        filtered_tokens.append(word)\n",
    "\n",
    "print(\"Filtered tokens: \",filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e23d6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed words:  ['feel', 'happy', 'today']\n"
     ]
    }
   ],
   "source": [
    "def stem(word):\n",
    "    if word.endswith(\"ing\"):\n",
    "        return word[:-3] #remove \"ing\" from the end of the word\n",
    "    return word\n",
    "\n",
    "stemmed_words=[]\n",
    "for word in filtered_tokens:\n",
    "    stemmed_words.append(stem(word))\n",
    "\n",
    "print(\"Stemmed words: \",stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df5df7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLP phase-2 : words to vectors\n",
    "#why vectors? because ml only understands numbers, so we must convert words into nnumbers.\n",
    "#Bag of words(BOW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1ea4600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer #will help us to convert text to count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0ab81fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"I am good\",\"i am happy\", \"happy today\",\" i am sad\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "972e5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize\n",
    "vectorizer = CountVectorizer() #create an object of CountVectorizer\n",
    "x= vectorizer.fit_transform(sentences) #learn vocabulary and convert sentences to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "105a5208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['am' 'good' 'happy' 'sad' 'today']\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary:\",vectorizer.get_feature_names_out()) #returns the vocabulary learned from the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "544f2d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors:\n",
      "[[1 1 0 0 0]\n",
      " [1 0 1 0 0]\n",
      " [0 0 1 0 1]\n",
      " [1 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectors:\")\n",
    "print(x.toarray()) \n",
    "#Here each row = sentence and each column = word from vocabulary\n",
    "#Each value= count of the word in the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9afce432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['also' 'am' 'good' 'is' 'learning' 'love' 'machine' 'python' 'with']\n",
      "\n",
      "Matrix:  \n",
      "[[0 1 0 0 1 0 0 1 0]\n",
      " [0 0 1 1 0 0 0 1 0]\n",
      " [1 0 0 0 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"I am learning python\",\"python is good\",\"i also love machine learning with python\"]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "x= vectorizer.fit_transform(sentences)\n",
    "print(\"Vocabulary:\",vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"\\nMatrix:  \")\n",
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd8ad1d",
   "metadata": {},
   "source": [
    "    TF-IDF- Term Frequency- Inverse Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "611a1f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bag of words treats all words ewually\n",
    "#For example: I am learning python,python and python\n",
    "#It will assign huge weight to python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdc10efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "sentences = [\"I am learning python\",\"python is good\",\"i also love machine learning with python\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "983e940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x= vectorizer.fit_transform(sentences) #internally it will build vocabulary,calculate tf and idf and then generates the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4771bb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['also' 'am' 'good' 'is' 'learning' 'love' 'machine' 'python' 'with']\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary:\",vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11f5ff5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix:\n",
      "[[0.         0.72033345 0.         0.         0.54783215 0.\n",
      "  0.         0.42544054 0.        ]\n",
      " [0.         0.         0.65249088 0.65249088 0.         0.\n",
      "  0.         0.38537163 0.        ]\n",
      " [0.45050407 0.         0.         0.         0.34261996 0.45050407\n",
      "  0.45050407 0.26607496 0.45050407]]\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF Matrix:\")\n",
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5b7ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"i am learning python and python is good\",\n",
    "#IDF calculation:\n",
    "#log[total documents/documents containing the word]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
