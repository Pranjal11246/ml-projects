{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3107b189",
   "metadata": {},
   "source": [
    "Intent Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67762630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# Second import sklearn dependencies\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c33f0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data= [\n",
    "    (\"hello\",\"great\"),\n",
    "    (\"hi there\",\"greet\"),\n",
    "    (\"good morning\",\"greet\"),\n",
    "    (\"hey\",\"greet\"),\n",
    "\n",
    "    (\"what's the weather today\",\"weather\"),\n",
    "    (\"tell me weather\",\"weather\"),\n",
    "    (\"is it raining\",\"weather\"),\n",
    "\n",
    "    (\"open\",\"open_app\"),\n",
    "    (\"oepn google\",\"open_app\"),\n",
    "    (\"open youtube\",\"open_app\"),\n",
    "    (\"bye\",\"exit\"),\n",
    "    (\"goodbye\",\"exit\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dfa09cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences= []\n",
    "labels= []\n",
    "\n",
    "for text, intent in training_data:\n",
    "    sentences.append(text)\n",
    "    labels.append(intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a98d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "# For removing stopwords\n",
    "from nltk.corpus import stopwords\n",
    "# For stemming and lemmatization\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import string\n",
    "punc = string.punctuation\n",
    "\n",
    "sentences = [\n",
    "    \"i am good\",\n",
    "    \"i am happy\",\n",
    "    \"happy today\",\n",
    "    \"i am sad\"\n",
    "]\n",
    "\n",
    "def preprocess_text(sentences):\n",
    "    cleaned_sentences = []\n",
    "    # Logic for text processing\n",
    "    # Step-1: Lowercase\n",
    "    for sentence in sentences:\n",
    "        text = sentence.lower()\n",
    "\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        punctuation_filter = [word for word in tokens if word not in punc]\n",
    "\n",
    "        eng_stopwords = stopwords.words(\"english\")\n",
    "        filtered_tokens = [word for word in punctuation_filter if word not in eng_stopwords]\n",
    "\n",
    "        wnet = WordNetLemmatizer()\n",
    "        lemmatized_words = []\n",
    "        for word in filtered_tokens:\n",
    "            lemmatized_words.append(wnet.lemmatize(word,\"v\"))\n",
    "        \n",
    "        \n",
    "        cleaned_text = \" \".join(lemmatized_words)\n",
    "        cleaned_sentences.append(cleaned_text) \n",
    "\n",
    "        \n",
    "    \n",
    "    return cleaned_sentences\n",
    "\n",
    "cleaned_text = preprocess_text(sentences)\n",
    "# expected output:\n",
    "# [\n",
    "#     \"good\",\"happy\",\"happy today\",\"sad\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f98ffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data=preprocess_text(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2778c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d603f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic= LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd11d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFittedError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m processed= preprocess_text([user_input])\n\u001b[32m      3\u001b[39m user_vector=vectorizer.transform(processed)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m prediction = \u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\linear_model\\_base.py:387\u001b[39m, in \u001b[36mLinearClassifierMixin.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[33;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[32m    375\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    384\u001b[39m \u001b[33;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[32m    385\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    386\u001b[39m xp, _ = get_namespace(X)\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores.shape) == \u001b[32m1\u001b[39m:\n\u001b[32m    389\u001b[39m     indices = xp.astype(scores > \u001b[32m0\u001b[39m, indexing_dtype(xp))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\linear_model\\_base.py:360\u001b[39m, in \u001b[36mLinearClassifierMixin.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    342\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    343\u001b[39m \u001b[33;03m    Predict confidence scores for samples.\u001b[39;00m\n\u001b[32m    344\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    358\u001b[39m \u001b[33;03m        this class would be predicted.\u001b[39;00m\n\u001b[32m    359\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    361\u001b[39m     xp, _ = get_namespace(X)\n\u001b[32m    363\u001b[39m     X = validate_data(\u001b[38;5;28mself\u001b[39m, X, accept_sparse=\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m, reset=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\utils\\validation.py:1705\u001b[39m, in \u001b[36mcheck_is_fitted\u001b[39m\u001b[34m(estimator, attributes, msg, all_or_any)\u001b[39m\n\u001b[32m   1702\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1704\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[32m-> \u001b[39m\u001b[32m1705\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg % {\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator).\u001b[34m__name__\u001b[39m})\n",
      "\u001b[31mNotFittedError\u001b[39m: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "user_input= \"hello there\"\n",
    "processed= preprocess_text([user_input])\n",
    "user_vector=vectorizer.transform(processed)\n",
    "logistic.fit(X, labels)\n",
    "prediction = logistic.predict(user_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
